{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bahaa\\anaconda3\\envs\\altantorch2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.10).\n",
      "Path to dataset files: C:\\Users\\bahaa\\.cache\\kagglehub\\datasets\\iamsouravbanerjee\\animal-image-dataset-90-different-animals\\versions\\5\n"
     ]
    }
   ],
   "source": [
    "from dataset import train_dataloaded,valid_dataloaded\n",
    "from main_model import data2vec_base\n",
    "model_teacher=data2vec_base(is_teacher=True,masking_ratio=0)\n",
    "model_student=data2vec_base(is_teacher=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR,CosineAnnealingWarmRestarts\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_teacher,model_student,train_dataloaded,valid_dataloaded):\n",
    "    model_teacher=model_teacher.to(\"cuda\")\n",
    "    model_student=model_student.to(\"cuda\")\n",
    "    train_dataloaded=train_dataloaded\n",
    "    valid_dataloaded=valid_dataloaded\n",
    "    \n",
    "\n",
    "    # Modelleri cihaza taşıyoruz\n",
    "    num_epochs=30\n",
    "    train_sets = len(train_dataloaded)\n",
    "    warmup_epochs=5\n",
    "\n",
    "    context_opt = torch.optim.AdamW(model_teacher.parameters(), lr=1e-4)\n",
    "    predictor_opt = torch.optim.AdamW(model_student.parameters(), lr=1e-4)\n",
    "    scheduler = get_cosine_schedule_with_warmup(predictor_opt,train_sets* warmup_epochs, train_sets * num_epochs)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "    train_losses = []\n",
    "    model_teacher.train()\n",
    "    model_student.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        total_loss_val=0.0\n",
    "        \n",
    "        for idx, (x, _) in enumerate(tqdm(train_dataloaded, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "            x = x.to(device)\n",
    "            \n",
    "            # context_model'den context, target ve target_indices elde ediliyor\n",
    "            context= model_teacher(x)\n",
    "            \n",
    "            # target_model'den hedef temsiller (target representations) alınıyor\n",
    "            context_student = model_student(x)\n",
    "           \n",
    "            \n",
    "            # Her bir hedef temsil için loss hesaplanıyor\n",
    "            \n",
    "                # predictor_model ile context temsilleri elde ediliyor.\n",
    "                # context.detach() ile geriye yayılımın target_model'e gitmesi engelleniyor.\n",
    "                    \n",
    "\n",
    "                        # Seçili patch'ler için uygun boyutta gürültü üret\n",
    "        \n",
    "                    \n",
    "                    \n",
    "                    # Loss: 1 - cosine_similarity, böylece negatif değer oluşması engelleniyor.\n",
    "            loss = criterion(context, context_student)\n",
    "                   \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "           \n",
    "            # Geriye yayılım\n",
    "            loss.backward()\n",
    "            \n",
    "            # Loss toplamına ekleme (skaler olarak)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Parametre güncellemesi\n",
    "            context_opt.step()\n",
    "            predictor_opt.step()\n",
    "            \n",
    "            context_opt.zero_grad()\n",
    "            predictor_opt.zero_grad()\n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "            \n",
    "            # CUDA kullanıyorsak senkronizasyon\n",
    "            \n",
    "        for idx,(images,label) in enumerate(tqdm(valid_dataloaded, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "            x = images.to(device)\n",
    "            \n",
    "            # context_model'den context, target ve target_indices elde ediliyor\n",
    "            context = model_teacher(x)\n",
    "            \n",
    "            # target_model'den hedef temsiller (target representations) alınıyor\n",
    "            context_student = model_student(x)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "            # Her bir hedef temsil için loss hesaplanıyor\n",
    "                \n",
    "                    # predictor_model ile context temsilleri elde ediliyor.\n",
    "                    # context.detach() ile geriye yayılımın target_model'e gitmesi engelleniyor.\n",
    "                    \n",
    "\n",
    "                        # Seçili patch'ler için uygun boyutta gürültü üret\n",
    "        \n",
    "                    \n",
    "                    \n",
    "                    # Loss: 1 - cosine_similarity, böylece negatif değer oluşması engelleniyor.\n",
    "                loss_i = criterion(context, context_student)\n",
    "                   \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                total_loss_val += loss_i.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                if device == \"cuda\":\n",
    "                    torch.cuda.synchronize()\n",
    "            # Öğrenme oranı güncellemesi\n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_dataloaded)\n",
    "        avg_loss_v=total_loss_val/len(valid_dataloaded)\n",
    "        train_losses.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {avg_loss:.6f} | Val Loss: {avg_loss_v:.6f}\")\n",
    "    \n",
    "    print(\"Finished Training\")\n",
    "    return train_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 135/135 [00:18<00:00,  7.39it/s]\n",
      "Epoch 1/30: 100%|██████████| 34/34 [00:08<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.183993 | Val Loss: 1.182499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 135/135 [00:18<00:00,  7.47it/s]\n",
      "Epoch 2/30: 100%|██████████| 34/34 [00:08<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 1.181896 | Val Loss: 1.178311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 135/135 [00:17<00:00,  7.50it/s]\n",
      "Epoch 3/30: 100%|██████████| 34/34 [00:08<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 1.175464 | Val Loss: 1.170092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 135/135 [00:18<00:00,  7.45it/s]\n",
      "Epoch 4/30: 100%|██████████| 34/34 [00:08<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 1.165426 | Val Loss: 1.158397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 135/135 [00:18<00:00,  7.47it/s]\n",
      "Epoch 5/30: 100%|██████████| 34/34 [00:08<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 1.152077 | Val Loss: 1.145162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 135/135 [00:17<00:00,  7.53it/s]\n",
      "Epoch 6/30: 100%|██████████| 34/34 [00:08<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 1.137961 | Val Loss: 1.129125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 135/135 [00:17<00:00,  7.61it/s]\n",
      "Epoch 7/30: 100%|██████████| 34/34 [00:08<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 1.122531 | Val Loss: 1.115409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: 100%|██████████| 135/135 [00:18<00:00,  7.20it/s]\n",
      "Epoch 8/30: 100%|██████████| 34/34 [00:08<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 1.107536 | Val Loss: 1.099226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: 100%|██████████| 135/135 [00:18<00:00,  7.43it/s]\n",
      "Epoch 9/30: 100%|██████████| 34/34 [00:08<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 1.092937 | Val Loss: 1.085670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: 100%|██████████| 135/135 [00:18<00:00,  7.45it/s]\n",
      "Epoch 10/30: 100%|██████████| 34/34 [00:08<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 1.078960 | Val Loss: 1.071650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: 100%|██████████| 135/135 [00:18<00:00,  7.33it/s]\n",
      "Epoch 11/30: 100%|██████████| 34/34 [00:08<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 1.066242 | Val Loss: 1.058403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: 100%|██████████| 135/135 [00:18<00:00,  7.25it/s]\n",
      "Epoch 12/30: 100%|██████████| 34/34 [00:08<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 1.053917 | Val Loss: 1.047835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: 100%|██████████| 135/135 [00:18<00:00,  7.26it/s]\n",
      "Epoch 13/30: 100%|██████████| 34/34 [00:08<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 1.043000 | Val Loss: 1.037640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: 100%|██████████| 135/135 [00:19<00:00,  6.96it/s]\n",
      "Epoch 14/30: 100%|██████████| 34/34 [00:08<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 1.032962 | Val Loss: 1.027951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|██████████| 135/135 [00:19<00:00,  6.82it/s]\n",
      "Epoch 15/30: 100%|██████████| 34/34 [00:08<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 1.024109 | Val Loss: 1.020272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: 100%|██████████| 135/135 [00:17<00:00,  7.62it/s]\n",
      "Epoch 16/30: 100%|██████████| 34/34 [00:08<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 1.016221 | Val Loss: 1.011552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: 100%|██████████| 135/135 [00:18<00:00,  7.35it/s]\n",
      "Epoch 17/30: 100%|██████████| 34/34 [00:08<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 1.009057 | Val Loss: 1.004527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: 100%|██████████| 135/135 [00:18<00:00,  7.47it/s]\n",
      "Epoch 18/30: 100%|██████████| 34/34 [00:08<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 1.002242 | Val Loss: 0.998800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: 100%|██████████| 135/135 [00:18<00:00,  7.41it/s]\n",
      "Epoch 19/30: 100%|██████████| 34/34 [00:08<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.996645 | Val Loss: 0.993443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: 100%|██████████| 135/135 [00:18<00:00,  7.49it/s]\n",
      "Epoch 20/30: 100%|██████████| 34/34 [00:08<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.991209 | Val Loss: 0.988640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: 100%|██████████| 135/135 [00:17<00:00,  7.52it/s]\n",
      "Epoch 21/30: 100%|██████████| 34/34 [00:08<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.986611 | Val Loss: 0.983873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: 100%|██████████| 135/135 [00:17<00:00,  7.53it/s]\n",
      "Epoch 22/30: 100%|██████████| 34/34 [00:08<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.982397 | Val Loss: 0.979648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|██████████| 135/135 [00:18<00:00,  7.39it/s]\n",
      "Epoch 23/30: 100%|██████████| 34/34 [00:08<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.978631 | Val Loss: 0.976515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: 100%|██████████| 135/135 [00:18<00:00,  7.45it/s]\n",
      "Epoch 24/30: 100%|██████████| 34/34 [00:08<00:00,  3.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.975176 | Val Loss: 0.972972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: 100%|██████████| 135/135 [00:18<00:00,  7.49it/s]\n",
      "Epoch 25/30: 100%|██████████| 34/34 [00:08<00:00,  3.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.972201 | Val Loss: 0.970237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: 100%|██████████| 135/135 [00:18<00:00,  7.48it/s]\n",
      "Epoch 26/30: 100%|██████████| 34/34 [00:08<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.969225 | Val Loss: 0.967157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: 100%|██████████| 135/135 [00:18<00:00,  7.29it/s]\n",
      "Epoch 27/30: 100%|██████████| 34/34 [00:08<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.966758 | Val Loss: 0.964696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: 100%|██████████| 135/135 [00:18<00:00,  7.37it/s]\n",
      "Epoch 28/30: 100%|██████████| 34/34 [00:08<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.964499 | Val Loss: 0.962612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: 100%|██████████| 135/135 [00:17<00:00,  7.53it/s]\n",
      "Epoch 29/30: 100%|██████████| 34/34 [00:08<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.962380 | Val Loss: 0.960411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: 100%|██████████| 135/135 [00:18<00:00,  7.46it/s]\n",
      "Epoch 30/30: 100%|██████████| 34/34 [00:08<00:00,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.960256 | Val Loss: 0.958510\n",
      "Finished Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model=train_model(model_teacher,model_student,train_dataloaded,valid_dataloaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reverse import Vec2Data\n",
    "vec2data=Vec2Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_teacher,model_student,vec2data,train_dataloaded,valid_dataloaded):\n",
    "    model_teacher=model_teacher.to(\"cuda\")\n",
    "    model_student=model_student.to(\"cuda\")\n",
    "    train_dataloaded=train_dataloaded\n",
    "    valid_dataloaded=valid_dataloaded\n",
    "    vec2data=vec2data.to(\"cuda\")\n",
    "\n",
    "    # Modelleri cihaza taşıyoruz\n",
    "    num_epochs=40\n",
    "    train_sets = len(train_dataloaded)\n",
    "    warmup_epochs=5\n",
    "\n",
    "    context_opt = torch.optim.AdamW(vec2data.parameters(), lr=1e-4)\n",
    "    \n",
    "    scheduler = get_cosine_schedule_with_warmup(context_opt,train_sets* warmup_epochs, train_sets * num_epochs)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "    train_losses = []\n",
    "    model_teacher.train()\n",
    "    model_student.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        total_loss_val=0.0\n",
    "        \n",
    "        for idx, (x, _) in enumerate(tqdm(train_dataloaded, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "            x = x.to(device)\n",
    "            \n",
    "            # context_model'den context, target ve target_indices elde ediliyor\n",
    "            context= model_teacher(x)\n",
    "            \n",
    "            # target_model'den hedef temsiller (target representations) alınıyor\n",
    "            context_student = model_student(x)\n",
    "           \n",
    "            reversed_t=vec2data(context)\n",
    "            reversed_st=vec2data(context)\n",
    "            # Her bir hedef temsil için loss hesaplanıyor\n",
    "            \n",
    "                # predictor_model ile context temsilleri elde ediliyor.\n",
    "                # context.detach() ile geriye yayılımın target_model'e gitmesi engelleniyor.\n",
    "                    \n",
    "\n",
    "                        # Seçili patch'ler için uygun boyutta gürültü üret\n",
    "        \n",
    "                    \n",
    "                    \n",
    "                    # Loss: 1 - cosine_similarity, böylece negatif değer oluşması engelleniyor.\n",
    "            loss = criterion(reversed_t, reversed_st)\n",
    "                   \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "           \n",
    "            # Geriye yayılım\n",
    "            loss.backward()\n",
    "            \n",
    "            # Loss toplamına ekleme (skaler olarak)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Parametre güncellemesi\n",
    "            context_opt.step()\n",
    "            \n",
    "            \n",
    "            context_opt.zero_grad()\n",
    "            \n",
    "            if device == \"cuda\":\n",
    "                torch.cuda.synchronize()\n",
    "            \n",
    "            # CUDA kullanıyorsak senkronizasyon\n",
    "            \n",
    "        for idx,(images,label) in enumerate(tqdm(valid_dataloaded, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "            x = images.to(device)\n",
    "            \n",
    "            # context_model'den context, target ve target_indices elde ediliyor\n",
    "            context = model_teacher(x)\n",
    "            \n",
    "            # target_model'den hedef temsiller (target representations) alınıyor\n",
    "            context_student = model_student(x)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "            # Her bir hedef temsil için loss hesaplanıyor\n",
    "                reversed_t=vec2data(context)\n",
    "                reversed_st=vec2data(context)\n",
    "            # Her bir hedef temsil için loss hesaplanıyor\n",
    "            \n",
    "                # predictor_model ile context temsilleri elde ediliyor.\n",
    "                # context.detach() ile geriye yayılımın target_model'e gitmesi engelleniyor.\n",
    "                    \n",
    "\n",
    "                        # Seçili patch'ler için uygun boyutta gürültü üret\n",
    "        \n",
    "                    \n",
    "                    \n",
    "                    # Loss: 1 - cosine_similarity, böylece negatif değer oluşması engelleniyor.\n",
    "                loss_i = criterion(reversed_t, reversed_st)\n",
    "                    # predictor_model ile context temsilleri elde ediliyor.\n",
    "                    # context.detach() ile geriye yayılımın target_model'e gitmesi engelleniyor.\n",
    "                    \n",
    "\n",
    "                        # Seçili patch'ler için uygun boyutta gürültü üret\n",
    "        \n",
    "                    \n",
    "                    \n",
    "                    # Loss: 1 - cosine_similarity, böylece negatif değer oluşması engelleniyor.\n",
    "                \n",
    "                   \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                total_loss_val += loss_i.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                if device == \"cuda\":\n",
    "                    torch.cuda.synchronize()\n",
    "            # Öğrenme oranı güncellemesi\n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_dataloaded)\n",
    "        avg_loss_v=total_loss_val/len(valid_dataloaded)\n",
    "        train_losses.append(avg_loss)\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {avg_loss:.6f} | Val Loss: {avg_loss_v:.6f}\")\n",
    "    \n",
    "    print(\"Finished Training\")\n",
    "    return train_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_student\u001b[49m\u001b[43m(\u001b[49m\u001b[43meleman\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bahaa\\anaconda3\\envs\\altantorch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bahaa\\anaconda3\\envs\\altantorch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\bahaa\\OneDrive\\Masaüstü\\data2vec_self\\environmen\\main_model.py:82\u001b[0m, in \u001b[0;36mdata2vec_base.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m#get the patch embeddings\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     b, n, e \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m#add positional embedding\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bahaa\\anaconda3\\envs\\altantorch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bahaa\\anaconda3\\envs\\altantorch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\bahaa\\OneDrive\\Masaüstü\\data2vec_self\\environmen\\patch_embdd.py:30\u001b[0m, in \u001b[0;36mPatchEmbed.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 30\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m#flatten the patches\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     x\u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bahaa\\anaconda3\\envs\\altantorch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bahaa\\anaconda3\\envs\\altantorch2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\bahaa\\anaconda3\\envs\\altantorch2\\lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bahaa\\anaconda3\\envs\\altantorch2\\lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "model_student(eleman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1931, 0.5779, 0.2499,  ..., 0.9439, 0.9774, 0.3176],\n",
       "          [0.8832, 0.3027, 0.5631,  ..., 0.7996, 0.1233, 0.3603],\n",
       "          [0.5700, 0.8214, 0.1535,  ..., 0.2904, 0.5488, 0.3477],\n",
       "          ...,\n",
       "          [0.0464, 0.6411, 0.6891,  ..., 0.8864, 0.4648, 0.2743],\n",
       "          [0.4772, 0.7408, 0.1261,  ..., 0.9153, 0.3407, 0.6088],\n",
       "          [0.2919, 0.8106, 0.1254,  ..., 0.3803, 0.5618, 0.2433]],\n",
       "\n",
       "         [[0.4280, 0.6545, 0.6576,  ..., 0.0451, 0.5562, 0.2568],\n",
       "          [0.0669, 0.3496, 0.8679,  ..., 0.1044, 0.4738, 0.6606],\n",
       "          [0.5818, 0.9670, 0.7874,  ..., 0.3265, 0.0478, 0.6208],\n",
       "          ...,\n",
       "          [0.1837, 0.5618, 0.5932,  ..., 0.6050, 0.2745, 0.2886],\n",
       "          [0.2545, 0.8251, 0.9152,  ..., 0.9774, 0.9630, 0.2012],\n",
       "          [0.5910, 0.3650, 0.8670,  ..., 0.2470, 0.5347, 0.3237]],\n",
       "\n",
       "         [[0.8482, 0.8139, 0.6881,  ..., 0.0855, 0.8455, 0.7415],\n",
       "          [0.4562, 0.8089, 0.2399,  ..., 0.9999, 0.6004, 0.2923],\n",
       "          [0.8477, 0.3447, 0.1927,  ..., 0.5100, 0.9762, 0.9708],\n",
       "          ...,\n",
       "          [0.4586, 0.6496, 0.4025,  ..., 0.3653, 0.2471, 0.9478],\n",
       "          [0.0938, 0.7654, 0.0421,  ..., 0.4625, 0.6727, 0.4296],\n",
       "          [0.8654, 0.9486, 0.4558,  ..., 0.7614, 0.1496, 0.2875]]],\n",
       "\n",
       "\n",
       "        [[[0.7171, 0.6833, 0.6464,  ..., 0.2671, 0.7501, 0.1565],\n",
       "          [0.9890, 0.3077, 0.3764,  ..., 0.2867, 0.7425, 0.4550],\n",
       "          [0.5742, 0.6414, 0.8305,  ..., 0.9842, 0.0969, 0.5817],\n",
       "          ...,\n",
       "          [0.7627, 0.9987, 0.8943,  ..., 0.1629, 0.6205, 0.5104],\n",
       "          [0.0975, 0.2625, 0.6598,  ..., 0.4620, 0.1982, 0.0601],\n",
       "          [0.1860, 0.4793, 0.2506,  ..., 0.4482, 0.5076, 0.7656]],\n",
       "\n",
       "         [[0.3701, 0.5417, 0.1166,  ..., 0.6491, 0.8203, 0.1914],\n",
       "          [0.3269, 0.2148, 0.8863,  ..., 0.1683, 0.6790, 0.8334],\n",
       "          [0.1502, 0.0151, 0.9457,  ..., 0.3153, 0.4492, 0.9443],\n",
       "          ...,\n",
       "          [0.2678, 0.5929, 0.2953,  ..., 0.9318, 0.0231, 0.5817],\n",
       "          [0.5259, 0.0359, 0.4558,  ..., 0.3890, 0.4685, 0.0319],\n",
       "          [0.8585, 0.4342, 0.7128,  ..., 0.5174, 0.6633, 0.6361]],\n",
       "\n",
       "         [[0.9309, 0.4518, 0.8122,  ..., 0.3265, 0.6849, 0.8082],\n",
       "          [0.7113, 0.3625, 0.3566,  ..., 0.1559, 0.0544, 0.3614],\n",
       "          [0.0743, 0.3902, 0.7691,  ..., 0.1180, 0.8726, 0.9682],\n",
       "          ...,\n",
       "          [0.8488, 0.7030, 0.7748,  ..., 0.7132, 0.1590, 0.8082],\n",
       "          [0.3356, 0.9469, 0.6108,  ..., 0.2118, 0.0826, 0.5202],\n",
       "          [0.8344, 0.9620, 0.3314,  ..., 0.3189, 0.4670, 0.9772]]],\n",
       "\n",
       "\n",
       "        [[[0.6774, 0.7473, 0.8549,  ..., 0.7231, 0.4261, 0.0793],\n",
       "          [0.5569, 0.9289, 0.9179,  ..., 0.4023, 0.5178, 0.2744],\n",
       "          [0.9766, 0.1005, 0.5445,  ..., 0.8121, 0.4244, 0.4505],\n",
       "          ...,\n",
       "          [0.3089, 0.3755, 0.4787,  ..., 0.9416, 0.4904, 0.5990],\n",
       "          [0.3113, 0.0412, 0.0389,  ..., 0.2167, 0.1567, 0.3702],\n",
       "          [0.7453, 0.9049, 0.4486,  ..., 0.5902, 0.1487, 0.5116]],\n",
       "\n",
       "         [[0.3756, 0.5160, 0.0270,  ..., 0.0767, 0.5024, 0.5807],\n",
       "          [0.4086, 0.3415, 0.5885,  ..., 0.8072, 0.0308, 0.3882],\n",
       "          [0.1413, 0.8079, 0.0136,  ..., 0.3546, 0.7894, 0.2693],\n",
       "          ...,\n",
       "          [0.8520, 0.8427, 0.0766,  ..., 0.0187, 0.1828, 0.4033],\n",
       "          [0.3056, 0.1553, 0.0058,  ..., 0.3009, 0.7114, 0.4674],\n",
       "          [0.8834, 0.0152, 0.3738,  ..., 0.9736, 0.6810, 0.9207]],\n",
       "\n",
       "         [[0.6009, 0.2453, 0.4082,  ..., 0.9515, 0.2831, 0.9297],\n",
       "          [0.1422, 0.5069, 0.1945,  ..., 0.5758, 0.6101, 0.6965],\n",
       "          [0.4747, 0.2325, 0.0951,  ..., 0.2562, 0.4378, 0.3950],\n",
       "          ...,\n",
       "          [0.6953, 0.7231, 0.3352,  ..., 0.4544, 0.4344, 0.4864],\n",
       "          [0.9408, 0.1548, 0.6763,  ..., 0.4890, 0.0059, 0.9312],\n",
       "          [0.5475, 0.9167, 0.8663,  ..., 0.8517, 0.4518, 0.6218]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.0684, 0.8531, 0.7137,  ..., 0.1318, 0.9634, 0.9265],\n",
       "          [0.4418, 0.1200, 0.0630,  ..., 0.1314, 0.2171, 0.1203],\n",
       "          [0.6710, 0.8514, 0.8664,  ..., 0.6387, 0.5324, 0.5259],\n",
       "          ...,\n",
       "          [0.5158, 0.3083, 0.6716,  ..., 0.6378, 0.4416, 0.3227],\n",
       "          [0.8621, 0.0849, 0.2041,  ..., 0.6433, 0.0137, 0.1172],\n",
       "          [0.9063, 0.1768, 0.6988,  ..., 0.2821, 0.9188, 0.7343]],\n",
       "\n",
       "         [[0.9932, 0.9915, 0.6076,  ..., 0.3843, 0.3154, 0.7139],\n",
       "          [0.7097, 0.0395, 0.1681,  ..., 0.2776, 0.1429, 0.2026],\n",
       "          [0.8819, 0.5543, 0.3058,  ..., 0.8731, 0.3353, 0.1929],\n",
       "          ...,\n",
       "          [0.8134, 0.0647, 0.6282,  ..., 0.6100, 0.9046, 0.0443],\n",
       "          [0.5114, 0.0717, 0.2820,  ..., 0.2465, 0.4351, 0.8043],\n",
       "          [0.9080, 0.9110, 0.3754,  ..., 0.8601, 0.7983, 0.5976]],\n",
       "\n",
       "         [[0.7745, 0.6510, 0.9085,  ..., 0.8526, 0.1711, 0.5091],\n",
       "          [0.3890, 0.1656, 0.6525,  ..., 0.6548, 0.0484, 0.8777],\n",
       "          [0.7196, 0.4356, 0.1068,  ..., 0.5573, 0.0220, 0.6788],\n",
       "          ...,\n",
       "          [0.1760, 0.3909, 0.2858,  ..., 0.0365, 0.7731, 0.1061],\n",
       "          [0.8414, 0.5728, 0.8151,  ..., 0.2078, 0.0789, 0.7025],\n",
       "          [0.9179, 0.2378, 0.7341,  ..., 0.2617, 0.0279, 0.5177]]],\n",
       "\n",
       "\n",
       "        [[[0.0600, 0.5250, 0.9779,  ..., 0.9748, 0.2487, 0.7594],\n",
       "          [0.6198, 0.4926, 0.3291,  ..., 0.7975, 0.4925, 0.3878],\n",
       "          [0.2206, 0.7829, 0.3955,  ..., 0.8614, 0.6886, 0.3410],\n",
       "          ...,\n",
       "          [0.3350, 0.2556, 0.8035,  ..., 0.9774, 0.0262, 0.3508],\n",
       "          [0.8424, 0.3275, 0.2704,  ..., 0.3260, 0.5256, 0.5149],\n",
       "          [0.5691, 0.3992, 0.1154,  ..., 0.4979, 0.4757, 0.6322]],\n",
       "\n",
       "         [[0.6136, 0.1811, 0.3058,  ..., 0.5683, 0.2252, 0.6269],\n",
       "          [0.8248, 0.3663, 0.5389,  ..., 0.1181, 0.9096, 0.4449],\n",
       "          [0.6563, 0.3644, 0.3038,  ..., 0.5369, 0.4412, 0.3156],\n",
       "          ...,\n",
       "          [0.3202, 0.3193, 0.2718,  ..., 0.2455, 0.6814, 0.7742],\n",
       "          [0.1171, 0.3142, 0.3597,  ..., 0.3729, 0.9881, 0.1099],\n",
       "          [0.3409, 0.4029, 0.6213,  ..., 0.7796, 0.9006, 0.0031]],\n",
       "\n",
       "         [[0.3124, 0.2451, 0.3485,  ..., 0.6549, 0.5865, 0.3524],\n",
       "          [0.3632, 0.3945, 0.7126,  ..., 0.3851, 0.8729, 0.8181],\n",
       "          [0.9524, 0.7008, 0.6723,  ..., 0.6914, 0.1083, 0.1595],\n",
       "          ...,\n",
       "          [0.2436, 0.6405, 0.4396,  ..., 0.4416, 0.8537, 0.9155],\n",
       "          [0.8697, 0.7766, 0.9475,  ..., 0.9405, 0.2672, 0.9505],\n",
       "          [0.7938, 0.9803, 0.6184,  ..., 0.0286, 0.6354, 0.1080]]],\n",
       "\n",
       "\n",
       "        [[[0.2925, 0.0861, 0.7278,  ..., 0.1743, 0.8032, 0.8978],\n",
       "          [0.6482, 0.5207, 0.2812,  ..., 0.5764, 0.8306, 0.5749],\n",
       "          [0.8111, 0.3306, 0.9090,  ..., 0.3208, 0.8851, 0.7228],\n",
       "          ...,\n",
       "          [0.7363, 0.7516, 0.4871,  ..., 0.5250, 0.9332, 0.3157],\n",
       "          [0.8931, 0.5712, 0.1483,  ..., 0.8701, 0.8647, 0.9453],\n",
       "          [0.1016, 0.1493, 0.8080,  ..., 0.4984, 0.1963, 0.6354]],\n",
       "\n",
       "         [[0.9543, 0.1481, 0.6750,  ..., 0.3674, 0.3172, 0.9698],\n",
       "          [0.0261, 0.5972, 0.8100,  ..., 0.0617, 0.5460, 0.5154],\n",
       "          [0.4833, 0.9610, 0.4050,  ..., 0.2574, 0.2765, 0.1710],\n",
       "          ...,\n",
       "          [0.7605, 0.1279, 0.3571,  ..., 0.9276, 0.2982, 0.9752],\n",
       "          [0.9750, 0.5142, 0.8664,  ..., 0.4535, 0.4585, 0.7671],\n",
       "          [0.6865, 0.6067, 0.7351,  ..., 0.8836, 0.6563, 0.4179]],\n",
       "\n",
       "         [[0.3719, 0.9464, 0.1120,  ..., 0.1912, 0.7605, 0.1995],\n",
       "          [0.6579, 0.1919, 0.3407,  ..., 0.7065, 0.0574, 0.8324],\n",
       "          [0.5064, 0.8588, 0.5720,  ..., 0.3725, 0.2759, 0.7990],\n",
       "          ...,\n",
       "          [0.5042, 0.9358, 0.6923,  ..., 0.6016, 0.0907, 0.2075],\n",
       "          [0.4785, 0.6874, 0.1256,  ..., 0.5776, 0.1461, 0.6351],\n",
       "          [0.7863, 0.9336, 0.3434,  ..., 0.4815, 0.8043, 0.0355]]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eleman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleman2=torch.stack([i.clone() for i in eleman])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 128, 128])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eleman2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eleman=torch.rand(32,64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 8, 8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diger=eleman.permute(0,2,1).reshape(32,64,8,8)\n",
    "diger.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(\n",
    "            64, 3, kernel_size=(1,1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineer=nn.Linear(8,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 8, 8])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(diger).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 128, 128])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.functional.interpolate(diger,(128,128),mode=\"bilinear\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altantorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
